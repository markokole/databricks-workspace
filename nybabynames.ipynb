{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5f12543-842a-4034-b710-2aebf84d2df1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import urllib\n",
    "\n",
    "# my_catalog = \"marko\"\n",
    "# my_schema = \"nybabynames\"\n",
    "# my_volume = \"names\"\n",
    "\n",
    "# spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {my_catalog}.{my_schema}\")\n",
    "# spark.sql(f\"CREATE VOLUME IF NOT EXISTS {my_catalog}.{my_schema}.{my_volume}\")\n",
    "\n",
    "# volume_path = f\"/Volumes/{my_catalog}/{my_schema}/{my_volume}/\"\n",
    "# download_url = \"https://health.data.ny.gov/api/views/jxy9-yhdk/rows.csv\"\n",
    "# filename = \"babynames.csv\"\n",
    "\n",
    "# urllib.request.urlretrieve(download_url, volume_path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3ecc12a-3f09-4519-8f03-1245a89f3321",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "import dlt\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Assign pipeline parameters to variables\n",
    "\n",
    "my_catalog = spark.conf.get(\"my_catalog\")\n",
    "my_schema = spark.conf.get(\"my_schema\")\n",
    "my_volume = spark.conf.get(\"my_volume\")\n",
    "\n",
    "# Define the path to source data\n",
    "\n",
    "volume_path = f\"/Volumes/{my_catalog}/{my_schema}/{my_volume}/\"\n",
    "\n",
    "# Define a streaming table to ingest data from a volume\n",
    "\n",
    "@dlt.table(\n",
    "  comment=\"Popular baby first names in New York. This data was ingested from the New York State Department of Health.\"\n",
    ")\n",
    "def baby_names_raw():\n",
    "  df = (spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"csv\")\n",
    "    .option(\"inferSchema\", True)\n",
    "    .option(\"header\", True)\n",
    "    .load(volume_path)\n",
    "  )\n",
    "  df_renamed_column = df.withColumnRenamed(\"First Name\", \"First_Name\")\n",
    "  return df_renamed_column\n",
    "\n",
    "# Define a materialized view that validates data and renames a column\n",
    "\n",
    "@dlt.table(\n",
    "  comment=\"New York popular baby first name data cleaned and prepared for analysis.\"\n",
    ")\n",
    "@dlt.expect(\"valid_first_name\", \"First_Name IS NOT NULL\")\n",
    "@dlt.expect_or_fail(\"valid_count\", \"Count > 0\")\n",
    "def baby_names_prepared():\n",
    "  return (\n",
    "    spark.read.table(\"baby_names_raw\")\n",
    "      .withColumnRenamed(\"Year\", \"Year_Of_Birth\")\n",
    "      .select(\"Year_Of_Birth\", \"First_Name\", \"Count\")\n",
    "  )\n",
    "\n",
    "# Define a materialized view that has a filtered, aggregated, and sorted view of the data\n",
    "\n",
    "@dlt.table(\n",
    "  comment=\"A table summarizing counts of the top baby names for New York for 2021.\"\n",
    ")\n",
    "def top_baby_names_2021():\n",
    "  return (\n",
    "    spark.read.table(\"baby_names_prepared\")\n",
    "      .filter(expr(\"Year_Of_Birth == 2021\"))\n",
    "      .groupBy(\"First_Name\")\n",
    "      .agg(sum(\"Count\").alias(\"Total_Count\"))\n",
    "      .sort(desc(\"Total_Count\"))\n",
    "      .limit(10)\n",
    "  )\n",
    "\n",
    "# Define a materialized view with all data from CSV\n",
    "\n",
    "@dlt.table(\n",
    "  comment=\"All data from CSV\"\n",
    ")\n",
    "\n",
    "def all_data():\n",
    "  return (\n",
    "    spark.read.table(\"baby_names_raw\")  \n",
    "  )\n",
    "\n",
    "# List all counties\n",
    "@dlt.table(\n",
    "  comment=\"All counties in the table\"\n",
    ")\n",
    "\n",
    "def all_counties():\n",
    "  df = spark.read.table(\"baby_names_raw\")\n",
    "  # df = df.withColumn(\"county\", df[\"county\"])\n",
    "  return df.withColumn(\"county\", initcap(df[\"county\"])).dropDuplicates([\"county\"]).select(\"county\")\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "nybabynames",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}